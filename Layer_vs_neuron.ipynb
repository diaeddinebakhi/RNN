{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 RNN with 1 Layer and 1 Neuron (üéá)\n",
    "You can always increase the number of neurons in an RNN. For the moment we'll stick with 1. We'll have 2 timesteps, 0 and 1. The Architecture of our `class` will look like the figure below:\n",
    "\n",
    "<img src='https://i.imgur.com/Nxa3XzS.png' width='400'>\n",
    "\n",
    "* `torch.mm()` - matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neural Network\n",
    "class RNNVanilla(nn.Module):\n",
    "    # __init__: the function where we create the architecture\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super(RNNVanilla, self).__init__()\n",
    "        \n",
    "        # Weights are random at first\n",
    "        # U contains connection weights for the inputs of the current time step\n",
    "        self.U = torch.randn(n_inputs, n_neurons) # for 1 neuron: size = 4 rows and 1 column\n",
    "        \n",
    "        # W contains connection weights for the outputs of the previous time step\n",
    "        self.W = torch.randn(n_neurons, n_neurons) # for 1 neuron: size = 1 row and 1 column\n",
    "        \n",
    "        # The bias\n",
    "        self.b = torch.zeros(1, n_neurons) # for 1 neuron: size = 1 row and 1 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 RNN with 1 Layer and Multiple Neurons (üéáüéáüéá)\n",
    "\n",
    "**Difference vs RNN 1 neuron 1 layer:**\n",
    "* size of output changes (because size of `n_neurons` changes)\n",
    "* size of the bias changes (it's the size of `n_neurons`) and `W` matrix\n",
    "    \n",
    "<img src='https://i.imgur.com/QV9nCUY.png' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Model:\n",
    "\n",
    "> Here is what's happening to the batch below:\n",
    "<img src='https://i.imgur.com/U5bzlIS.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 28: The number of **time steps** in the sequence. This means that the input is divided into 28 parts (one for each time step).\n",
    "- 64: The **batch size**, indicating there are 64 separate sequences (samples) processed in parallel.\n",
    "- 28: The **input size** (or number of features),(number of inputs) at each time step. Each time step in each sequence has 28 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/U5bzlIS.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Sizes in the RNN Layer:\n",
    "- Input Sequence: (28,64,28)\n",
    "- Initial Hidden State: (64,150)\n",
    "- Weight Matrix ùëà\n",
    "    - U:(28,150)\n",
    "- Weight Matrix ùëä\n",
    "    - W:(150,150)\n",
    "\n",
    "- Bias ùëè\n",
    "    - b:(150,)\n",
    "\n",
    "- Intermediate Computations at Each Time Step:ùë•ùë°\n",
    "    - xt:(64,28)\n",
    "\n",
    "    - ùëà‚ãÖùë•ùë°:(64,150)\n",
    "\n",
    "    - ‚Ñéùë°‚àí1:(64,150)\n",
    "\n",
    "    - ùëä‚ãÖ‚Ñéùë°‚àí1 : (64,150)\n",
    "\n",
    "    - ‚Ñéùë°:(64,150)\n",
    "\n",
    "- Final Hidden State (after all time steps): (64,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[64,28,28] --- [28,64,28] --- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/U5bzlIS.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- original images shape: torch.Size([64, 1, 28, 28])\n",
    "- changed images shape: torch.Size([64, 28, 28])\n",
    "- labels shape: torch.Size([64]) \n",
    "________________________________________\n",
    "- Original Images Shape: torch.Size([64, 28, 28])\n",
    "- Permuted Imaged Shape: torch.Size([28, 64, 28])\n",
    "- Initial hidden state Shape: torch.Size([1, 64, 150])\n",
    "- ----hidden_outputs shape: torch.Size([28, 64, 150]) \n",
    "- ----final hidden state: torch.Size([1, 64, 150]) \n",
    "- ----out shape: torch.Size([1, 64, 10])\n",
    "- Out Final Shape: torch.Size([64, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/j2Yto51.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- original images shape: torch.Size([64, 1, 28, 28])\n",
    "- reshaped images shape: torch.Size([64, 28, 28]) \n",
    "\n",
    "- MultilayerRNN_MNIST(\n",
    "  - (rnn): RNN(28, 100, num_layers=2, batch_first=True)\n",
    "  - (fnn): Linear(in_features=100, out_features=10, bias=True)\n",
    ")\n",
    "______\n",
    "- images shape: torch.Size([64, 28, 28])\n",
    "- Hidden State shape: torch.Size([2, 64, 100])\n",
    "- RNN Output shape: torch.Size([64, 28, 100]) \n",
    "- RNN last_hidden_state shape torch.Size([2, 64, 100])\n",
    "- FNN Output shape: torch.Size([64, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/NIHrqIO.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Why the Difference in Permutation ?\n",
    "\n",
    "- The need for permutation depends on how the RNN layer is implemented or what input shape it expects.\n",
    "In practice, PyTorch RNN modules by default expect [sequence_length, batch_size, input_size], but some custom or higher-level APIs might allow [batch_size, sequence_length, input_size] directly, particularly when handling multiple layers where internal reshaping is managed automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
