{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 RNN with 1 Layer and 1 Neuron (🎇)\n",
    "You can always increase the number of neurons in an RNN. For the moment we'll stick with 1. We'll have 2 timesteps, 0 and 1. The Architecture of our `class` will look like the figure below:\n",
    "\n",
    "<img src='https://i.imgur.com/Nxa3XzS.png' width='400'>\n",
    "\n",
    "* `torch.mm()` - matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Neural Network\n",
    "class RNNVanilla(nn.Module):\n",
    "    # __init__: the function where we create the architecture\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        super(RNNVanilla, self).__init__()\n",
    "        \n",
    "        # Weights are random at first\n",
    "        # U contains connection weights for the inputs of the current time step\n",
    "        self.U = torch.randn(n_inputs, n_neurons) # for 1 neuron: size = 4 rows and 1 column\n",
    "        \n",
    "        # W contains connection weights for the outputs of the previous time step\n",
    "        self.W = torch.randn(n_neurons, n_neurons) # for 1 neuron: size = 1 row and 1 column\n",
    "        \n",
    "        # The bias\n",
    "        self.b = torch.zeros(1, n_neurons) # for 1 neuron: size = 1 row and 1 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 RNN with 1 Layer and Multiple Neurons (🎇🎇🎇)\n",
    "\n",
    "**Difference vs RNN 1 neuron 1 layer:**\n",
    "* size of output changes (because size of `n_neurons` changes)\n",
    "* size of the bias changes (it's the size of `n_neurons`) and `W` matrix\n",
    "    \n",
    "<img src='https://i.imgur.com/QV9nCUY.png' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Model:\n",
    "\n",
    "> Here is what's happening to the batch below:\n",
    "<img src='https://i.imgur.com/U5bzlIS.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 28: The number of **time steps** in the sequence. This means that the input is divided into 28 parts (one for each time step).\n",
    "- 64: The **batch size**, indicating there are 64 separate sequences (samples) processed in parallel.\n",
    "- 28: The **input size** (or number of features),(number of inputs) at each time step. Each time step in each sequence has 28 features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://i.imgur.com/U5bzlIS.png' width=500>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary of Sizes in the RNN Layer:\n",
    "- Input Sequence: (28,64,28)\n",
    "- Initial Hidden State: (64,150)\n",
    "- Weight Matrix 𝑈\n",
    "    - U:(28,150)\n",
    "- Weight Matrix 𝑊\n",
    "    - W:(150,150)\n",
    "\n",
    "- Bias 𝑏\n",
    "    - b:(150,)\n",
    "\n",
    "- Intermediate Computations at Each Time Step:𝑥𝑡\n",
    "    - xt:(64,28)\n",
    "\n",
    "    - 𝑈⋅𝑥𝑡:(64,150)\n",
    "\n",
    "    - ℎ𝑡−1:(64,150)\n",
    "\n",
    "    - 𝑊⋅ℎ𝑡−1 : (64,150)\n",
    "\n",
    "    - ℎ𝑡:(64,150)\n",
    "\n",
    "- Final Hidden State (after all time steps): (64,150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[64,28,28] --- [28,64,28] --- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
